{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'opensoundscape.ml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m roc_auc_score\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopensoundscape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshallow_classifier\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quick_fit \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#pixi run pip install git+https://github.com/kitzeslab/opensoundscape.git\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#pixi run pip install git+https://github.com/kitzeslab/bioacoustics-model-zoo@0.11.0\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhashlib\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'opensoundscape.ml'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from opensoundscape.ml.shallow_classifier import quick_fit \n",
    "#pixi run pip install git+https://github.com/kitzeslab/opensoundscape.git\n",
    "#pixi run pip install git+https://github.com/kitzeslab/bioacoustics-model-zoo@0.11.0\n",
    "\n",
    "import hashlib\n",
    "import datetime\n",
    "import getpass\n",
    "\n",
    "import random\n",
    "import torch\n",
    "\n",
    "\n",
    "def create_train_sizes(df):\n",
    "    rows_to_remove_per_iteration = 10\n",
    "    dataframes_list = {}\n",
    "\n",
    "    # Start with the original DataFrame as the largest train size\n",
    "    label = f\"train_size_{len(df)}\"\n",
    "    dataframes_list[label] = df.copy()\n",
    "\n",
    "    # Subsequently remove rows to reduce size\n",
    "    current_df = df.copy()\n",
    "    iteration = 1\n",
    "    while len(current_df) > rows_to_remove_per_iteration * 2:\n",
    "        # Separate into positive and negative groups\n",
    "        df_neg = current_df[current_df[\"present\"] == False]\n",
    "        df_pos = current_df[current_df[\"present\"] == True]\n",
    "\n",
    "        if len(df_neg) < rows_to_remove_per_iteration or len(df_pos) < rows_to_remove_per_iteration:\n",
    "            print(\"Not enough rows to continue sampling.\")\n",
    "            break\n",
    "\n",
    "        neg_to_remove = df_neg.sample(n=rows_to_remove_per_iteration, random_state=iteration)\n",
    "        pos_to_remove = df_pos.sample(n=rows_to_remove_per_iteration, random_state=iteration)\n",
    "        rows_to_remove = pd.concat([neg_to_remove, pos_to_remove])\n",
    "        current_df = current_df.drop(rows_to_remove.index)\n",
    "\n",
    "        label = f\"train_size_{len(current_df)}\"\n",
    "        dataframes_list[label] = current_df.copy()\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    return dataframes_list\n",
    "\n",
    "\n",
    "def process_species_model(species, model_name, audio_dir, results_dir, batch_size, epoch, learning_rate):\n",
    "    \"\"\"\n",
    "    Processes a given species and model by training and evaluating the model.\n",
    "    \"\"\"\n",
    "    train_df = pd.read_csv(f\"{audio_dir}/{species}/train_files.csv\")\n",
    "    test_df = pd.read_csv(f\"{audio_dir}/{species}/test_files.csv\")\n",
    "    \n",
    "    if model_name == 'Perch':\n",
    "        train_df['file'] = train_df['file'].str.replace('data', 'data_5s')\n",
    "        test_df['file'] = test_df['file'].str.replace('data', 'data_5s')\n",
    "        pd.set_option('display.max_colwidth', 100)\n",
    "        print(train_df)\n",
    "    \n",
    "    train_df['file'] = train_df['file'].astype(str)\n",
    "    test_df['file'] = test_df['file'].astype(str)\n",
    "    train_df.set_index(\"file\", inplace=True)\n",
    "    test_df.set_index(\"file\", inplace=True)\n",
    "    \n",
    "    # Create train sizes\n",
    "    dataframes_list = create_train_sizes(train_df)\n",
    "    \n",
    "    # Load model\n",
    "    model = torch.hub.load('kitzeslab/bioacoustics-model-zoo', model_name, trust_repo=True)\n",
    "    model.change_classes(['present'])\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Iterate through train sizes and train/test\n",
    "    for train_size, i in dataframes_list.items():\n",
    "        train = pd.DataFrame(i)\n",
    "        emb_train = model.embed(train, return_dfs=False, batch_size=batch_size, num_workers=0)\n",
    "        emb_val = model.embed(test_df, return_dfs=False, batch_size=batch_size, num_workers=0)\n",
    "        \n",
    "        quick_fit(model.network, emb_train, train.values, emb_val, test_df.values, steps=1000)\n",
    "        \n",
    "        predictions = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "        score = roc_auc_score(test_df.values, predictions, average=None)\n",
    "        \n",
    "        results.append({'train_size': train_size, model_name: score})\n",
    "    \n",
    "    # Train size 0\n",
    "    emb_val0 = model.embed(test_df, return_dfs=False, batch_size=batch_size, num_workers=0)\n",
    "    predictions0 = model.network(torch.tensor(emb_val0).float()).detach().numpy()\n",
    "    score0 = roc_auc_score(test_df.values, predictions0, average=None)\n",
    "    results.append({'train_size': 'train_size_0', model_name: score0})\n",
    "    \n",
    "    # Generate unique hash\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    username = getpass.getuser()\n",
    "    unique_hash = hashlib.md5(f\"{timestamp}_{username}\".encode()).hexdigest()[:8]\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(f\"{results_dir}/{species}-{model_name}-{batch_size}-{epoch}-{learning_rate}.csv\", index=False)\n",
    "\n",
    "\n",
    "def run_training(species_list, model_list, audio_dir, results_dir, batch_size, epoch, learning_rate):\n",
    "    \"\"\"\n",
    "    Runs the training process for multiple species and models.\n",
    "    \"\"\"\n",
    "    for species in species_list:\n",
    "        for model_name in model_list:\n",
    "            process_species_model(species, model_name, audio_dir, results_dir, batch_size, epoch, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "SPECIES_LIST = ['human_vocal'] # , 'engine', 'woodhouses_toad','pacific_chorus_frog','bullfrog','field_cricket','coyote']\n",
    "AUDIO_DIR = \"/workspaces/bird_new/data/non-avian_ML/audio\"\n",
    "RESULTS_DIR = \"/workspaces/bird_new/data/non-avian_ML/results\"\n",
    "\n",
    "MODEL_LIST = ['BirdNET', 'Perch']\n",
    "BATCH_SIZE = 128\n",
    "EPOCH = 'NA'\n",
    "LEARNING_RATE = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training(SPECIES_LIST, MODEL_LIST, AUDIO_DIR, RESULTS_DIR, BATCH_SIZE, EPOCH, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### old code\n",
    "\n",
    "for SPECIES in SPECIES_LIST:\n",
    "    for MODEL in MODEL_LIST: \n",
    "        train_df = pd.read_csv(f\"{AUDIO_DIR}/{SPECIES}/train_files.csv\")\n",
    "        test_df = pd.read_csv(f\"{AUDIO_DIR}/{SPECIES}/test_files.csv\")\n",
    "        \n",
    "        if MODEL == 'Perch':\n",
    "            train_df['file'] = train_df['file'].str.replace('data', 'data_5s')\n",
    "            test_df['file'] = test_df['file'].str.replace('data', 'data_5s')\n",
    "            pd.set_option('display.max_colwidth', 100)\n",
    "            print(train_df)\n",
    "        train_df['file'] = train_df['file'].astype(str)\n",
    "        test_df['file'] = test_df['file'].astype(str)\n",
    "        \n",
    "        train_df.set_index(\"file\", inplace=True)\n",
    "        test_df.set_index(\"file\", inplace=True)\n",
    "        \n",
    "        # Create train sizes and store in a variable\n",
    "        dataframes_list = create_train_sizes(train_df)\n",
    "\n",
    "        # Load model\n",
    "        model = torch.hub.load('kitzeslab/bioacoustics-model-zoo', MODEL, trust_repo=True)\n",
    "\n",
    "        results = []\n",
    "\n",
    "        # Iterate through train sizes and train/test\n",
    "        for train_size, i in dataframes_list.items():\n",
    "            train = pd.DataFrame(i)\n",
    "\n",
    "            emb_train = model.embed(train, return_dfs=False, batch_size=BATCH_SIZE, num_workers=0)\n",
    "            emb_val = model.embed(test_df, return_dfs=False, batch_size=BATCH_SIZE, num_workers=0)\n",
    "\n",
    "            model.change_classes(['present'])\n",
    "\n",
    "            quick_fit(model.network, emb_train, train.values, emb_val, test_df.values, steps=1000)\n",
    "\n",
    "            predictions = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "            score = roc_auc_score(test_df.values, predictions, average=None)\n",
    "\n",
    "            results.append({'train_size': train_size, MODEL: score})\n",
    "\n",
    "        # Train size 0 \n",
    "        emb_val0 = model.embed(test_df, return_dfs=False, batch_size=BATCH_SIZE, num_workers=0)\n",
    "        predictions0 = model.network(torch.tensor(emb_val0).float()).detach().numpy()\n",
    "        score0 = roc_auc_score(test_df.values, predictions0, average=None)\n",
    "        results.append({'train_size': 'train_size_0', MODEL: score0})\n",
    "\n",
    "        # Generate unique hash from timestamp and username\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        username = getpass.getuser()\n",
    "        unique_hash = hashlib.md5(f\"{timestamp}_{username}\".encode()).hexdigest()[:8]  # Shorten hash\n",
    "\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(f\"{RESULTS_DIR}/{SPECIES}-{MODEL}-{BATCH_SIZE}-{EPOCH}-{LEARNING_RATE}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
